---
title: "Spatial Data Source Validation ‚Äî Level I"
author: "CJ Tinant"
date: "`r format(Sys.Date(), '%Y-%m-%d')`"
output: html_document
---

# Overview

This document supports QA of raw spatial inputs used for regional skew modeling. The goal is to inventory, validate, and deduplicate vector and raster files within the `data/raw/` directory prior to covariate extraction.

## Goals

-   ‚úÖ Identify and remove duplicate files from `data/raw/vector_raw`
-   ‚úÖ Deduplicate and standardize raster inputs in `data/raw/raster_raw`
-   üóÇÔ∏è Organize spatial datasets by relevance, format, and source
-   üìù Document retained files in `data/meta/spatial_source_checklist.csv`

## Workflow: Deduplication of Vector Spatial Files

### 1. Inventory Vector Files

- List vector files recursively and flag potential duplicates

### 2. Summarize by Name and Size

- Group by basename
- Highlight different file sizes as potential version conflicts
- Flag preferred formats (e.g., keep `.gpkg`, review `.shp`)

### 3. Save Results to CSV

**Exported outputs:**
- `to_check/vector_file_inventory.csv` ‚Äì full file list with duplicate flags
- `to_check/duplicate_vector_summary.csv` ‚Äì filtered table of same-name files

### 4. Draft Cleanup Plan

- Move lower-priority duplicates to `to_check/duplicates/`
- Confirm projections and attribute consistency before deletion

### 5. Documentation

- Add exploratory summaries and notes on retained files
- Optionally create `data/meta/spatial_source_checklist.csv`
- Tag major cleanup step as `v0.3.1-dedup-raw-vector`
- Append to `milestone_02_documentation.Rmd`

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(sf)              # simple features in R
library(fs)              # file system operations
library(here)            # find files
library(tidyverse)

file.exists(here("R/utils/dedup_vector_inventory.R"))

source(here("R/utils/dedup_vector_inventory.R"))
source(here("R/utils/move_low_priority_duplicates.R"))


```

### Run Deduplication Inventory Function

```{r run-dedup-function}

result <- dedup_vector_inventory()

```

### Preview Cleanup Recommendations

```{r make_cleanup_checklist_table}
result$duplicates %>%
  mutate(action = if_else(file_type == "gpkg", "üü¢ keep", "üî¥ review")) %>%
  select(basename, file_type, size_mb, action) %>%
  distinct() %>%
  arrange(basename) %>%
  knitr::kable(caption = "Initial Cleanup Recommendations")
```

```{r move_duplicates}

move_low_priority_duplicates()

```

```{r}

source(here("R/utils/organize_raw_shapefiles.R"))
shapefile_reorg <- readr::read_csv(here("to_check/shapefile_reorg_log.csv"))

```



```{r check_crs}

# Get list of vector files from earlier
vector_paths <- result$vector_files$path

# Safely read each and extract the CRS string (WKT or EPSG)
crs_check <- tibble(
  path = vector_paths,
  basename = path_file(path),
  file_type = tools::file_ext(path),
  crs = map_chr(path, ~ tryCatch(
    st_crs(read_sf(.x))$input,
    error = function(e) NA_character_
  ))
)

# View summary table of CRS
crs_summary <- crs_check %>%
  count(crs, sort = TRUE)

print(crs_summary)
```

```{r flag_missing_crs}

# Flag missing CRS
crs_check %>%
  filter(is.na(crs)) %>%
  select(basename, path)

```

