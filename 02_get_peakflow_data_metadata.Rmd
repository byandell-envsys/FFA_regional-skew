---
title: "Regional skew coefficient analysis "
subtitle: "Clean data
author: "CJ Tinant"
date: "`r Sys.Date()`"
output: html_document
---

<!--
Purpose: Iteratively visualize and select ecoregions for AOI

Overview:
* load and process spatial data -- currently only locally works
-- imports and validates shapefiles
-- returns spatial objects with centroid and coordinates

* iteratively visualize and select ecoregions for AOI

* export results

# Next steps:
* fix CyVerse to work with the data

# References:
https://github.com/EmilHvitfeldt/r-color-palettes
https://r.geocompx.org/
-->

```{r 00_setup, include=FALSE}

knitr::opts_chunk$set(echo = TRUE)

# library
library(tidyverse)        # Load the 'Tidyverse' packages: ggplot2, dplyr, 
                          #   tidyr, readr, purrr, tibble, stringr, and forcats
library(dataRetrieval)    # Retrieval functions for USGS and EPA hydrology and
                          #   water quality data
library(sf)               # Simple features for R
library(here)

# Functions:
# process_geometries -- written with ChatGPT 4.0 on 2024-06-06
#     The function returns a modified sf object with additional columns for
#     the centroid and its coordinates.
# The function automates the following functions:
#     Check and make geometries valid
#         eco_l3$geometry <- st_make_valid(eco_l3$geometry)
#     Safely calculate centroids for valid geometries
#         eco_l3$centroid <- ifelse(st_is_valid(eco_l3$geometry),
#                                   st_centroid(eco_l3$geometry), NA)
#      Extract coordinates from centroids
#          eco_l3$text_x <- ifelse(!is.na(eco_l3$centroid),
#                                  st_coordinates(eco_l3$centroid)[, 1],
#                                  NA)
#          eco_l3$text_y <- ifelse(!is.na(eco_l3$centroid),
#                                  st_coordinates(eco_l3$centroid)[, 2],
#                                  NA)
#
# Details about process_geometries:
# Geometry Validation:
#   st_make_valid() is used to correct any invalid geometries within the
#     spatial data frame. The function identifies indices of valid geometries
#     to ensure that centroids and subsequent operations are only applied to
#     them.
# Centroid Calculation:
#   st_centroid() is applied conditionally only to valid geometries using
#     ifelse().
#   If a geometry is invalid, NA is used as a fallback.
#      st_centroid() is applied only to the valid parts of the geometry column.
#   Centroids are stored in a list to handle any type of geometry being returned
#      from st_centroid().
#   Each geometry is processed individually within a loop to allow more control
#      over handling each item and better debugging capabilities if errors occur.
#   !is_empty(centroid) checks if the centroid is not empty. 
#   The function also ensures that st_coordinates(centroid) actually returns
#      a non-empty data frame before trying to access its elements.
# Conditional Coordinates Extraction:
#   The x and y coordinates are extracted from the centroid. If the centroid
#      is NA (because the geometry was invalid), the coordinate fields are set
#      to NA.
#   Coordinates are extracted only if there are valid centroids. This is
#      safeguarded by checking if there are valid indices before attempting to
#      extract coordinates.
#   text_x and text_y are initialized with NA_real_ to ensure that the type
#      consistency is maintained for cases where centroids might not be
#      computable.
#   Before extracting coordinates, the function checks if the centroid is not NA
#      and contains rows. Then it ensures that the coordinates can be indexed
#      properly, and has the required number of columns 
#        (at least two, for x and y coordinates).
# Additional checks:
#   Separate Checks for NAs and Data Structure Validity: The function checks
#       for NAs and the structure of coords are now more explicit.
#     The function checks if centroid is not NA and not empty. Then, if coords
#       is derived, the function ensures it is not NA and has the necessary rows
#       and columns.
#   Avoid Coercion Errors: By ensuring each part of the conditional is valid
#       before evaluating the next part, this prevents logical operations on
#       possibly undefined or inappropriate data types.
#   Direct Evaluation of Conditions: The logic is structured to progressively
#       verify conditions before accessing potentially problematic attributes
#       like the number of rows or columns.
#   Check for null in coords: The function ensures that coords is not null
#       before proceeding to check its dimensions. This prevents logical errors
#       when coords might be an unexpected type or structure.
#   Explicit Structure Check: By using is.null along with checks for the number
#       of rows and columns in coords, the function can more reliably ensure
#       that the data structure is correct before attempting to access its
#       elements.

process_geometries <- function(sf_object) {
  # Ensure all geometries are valid
  sf_object$geometry <- st_make_valid(sf_object$geometry)
  
  # Initialize columns for centroids and coordinates
  sf_object$text_x <- rep(NA_real_, nrow(sf_object))
  sf_object$text_y <- rep(NA_real_, nrow(sf_object))

  # Calculate centroids for valid geometries and extract coordinates
  for (i in seq_len(nrow(sf_object))) {
    if (st_is_valid(sf_object$geometry[i])) {
      centroid <- st_centroid(sf_object$geometry[i])
      if (!is.na(centroid) && !st_is_empty(centroid)) {
        coords <- st_coordinates(centroid)
        # Explicit check for coords' validity and structure
        if (!is.null(coords) && nrow(coords) > 0 && ncol(coords) >= 2) {
          sf_object$text_x[i] <- coords[1, 1]
          sf_object$text_y[i] <- coords[1, 2]
        }
      }
    }
  }

  # Return the modified sf object
  return(sf_object)
}

```

## Get data -- either from Cyverse or locally
```{r 01a_get_and_clean_data_local}

# load shapefiles -- local path -- and check geometry
file_path <- "data_spatial/"

# usa ecoregions level 3
file_name <- "us_eco_l3/us_eco_l3.shp"
eco_l3 <- st_read(paste(file_path,
                        file_name,
                        sep = "")) %>%
  janitor::clean_names() %>%
  process_geometries()

# usa states
file_name <- "tl_2012_us_state/tl_2012_us_state.shp"
state_bdy_usa <- st_read(paste(file_path,
                        file_name,
                        sep = "")) %>%
  janitor::clean_names() %>%
  process_geometries()

# usa tribal lands
file_name <- "tl_2020_us_aitsn/tl_2020_us_aitsn.shp"
tribal_lands_usa <- st_read(paste(file_path,
                        file_name,
                        sep = "")) %>%
  janitor::clean_names() %>%
  process_geometries()

# census codes for American Indian, Alaska Native, and
#   Native Hawaiian Areas (AIANNH) 2020 ----
#     https://www.census.gov/library/reference/code-lists/ansi.html
#   need to pivot the data because tribal lands in multiple states
file_path <- "data_spatial/metadata/"
file_name <- "national_aiannh2020.csv"

aiannh_table <- read_csv(paste(file_path, file_name, sep = "")) %>%
  janitor::clean_names()

# clean up Global Environment
rm(list = ls(pattern = "file"))
rm(list = ls(pattern = "process"))

```

```{r 01b_get_and_clean_data_Cyverse, eval=FALSE}

# load shapefiles -- local path -- and check geometry
eco_l3 <- st_read("data_spatial/us_eco_l3/us_eco_l3.shp") %>%
  janitor::clean_names() %>%
  process_geometries()

eco_l4 <- st_read("data_spatial/us_eco_l4/us_eco_l4_no_st.shp") %>%
  janitor::clean_names() %>%
  process_geometries()

state_bdy <- st_read("data_spatial/tl_2012_us_state/tl_2012_us_state.shp") %>%
  janitor::clean_names() %>%
  process_geometries()

tribal_lands_usa <- st_read("data_spatial/tl_2020_us_aitsn/tl_2020_us_aitsn.shp") %>%
  janitor::clean_names() %>%
  process_geometries()

# load 2020 Census codes for American Indian, Alaska Native, and
#   Native Hawaiian Areas (AIANNH)----
#     https://www.census.gov/library/reference/code-lists/ansi.html
#   need to pivot the data because tribal lands in multiple states
file_path <- "data_spatial/metadata/"
file_name <- "national_aiannh2020.csv"

aiannh_table <- read_csv(paste(file_path, file_name, sep = "")) %>%
  janitor::clean_names() %>%
  separate_wider_delim(
    cols = states,
    delim = "~",
    names = c("scratch_1", "scratch_2", "scratch_3"),
    too_few = "align_start",
    too_many = "merge"
    ) %>%
  pivot_longer(cols = starts_with("scratch"),
               names_to = "scratch",
               values_to = "states") %>%
  select(-scratch) %>%
  filter(!is.na(states))

```

## Visualize ecoregions and select study area

```{r 02a_intersect_eco_l3_bdry_w_rm_gp_region}

# This code chunk intersects eco_l3 with the RM and GP region boundary for
#   Indian Lands of Federally Recognized Tribes of the United States
#   1. filter the tribal lands in Rocky Mountain and Great Plains regions
#         start with selecting census codes for states in RM and GP ecoregions;
#   2. check shapefiles geometry
#   3. Reproject ecoregion shapefile to NAD83 Geographic (ESPG:4269) -- Lat Lon
#   4. Filter States in Rocky Mountain and Great Plains regions
#   5. Make a single polygon of the Rocky Mountain and Great Plains regions

# select the census codes for states in Rocky Mountain and Great Plains regions
aiannh_rm_gp <- aiannh_table %>%
  filter(states == "SD" |
         states == "ND" |
         states == "NE" |
         states == "MT" |
         states == "WY"
           )

# filter the tribal lands in Rocky Mountain and Great Plains regions
tribal_lands_rm_gp <- tribal_lands_usa %>%
  filter(aiannhce %in% aiannh_rm_gp$aiannhce)

# check geometry of shapefiles
crs_geom_eco <- eco_l3 %>%
  st_crs() %>%
  pluck(.,1)

crs_geom_st_bdy_usa <- state_bdy_usa %>%
  st_crs() %>%
  pluck(.,1)

# reproject ecoregions to NAD83 Geographic (ESPG:4269) -- Lat Lon
eco_l3_proj <- eco_l3 %>%
  st_transform(crs = 4269)

# filter States in Rocky Mountain and Great Plains regions
state_bdy <- state_bdy_usa %>%
  filter(stusps == "SD" |
         stusps == "ND" |
         stusps == "NE" |
         stusps == "MT" |
         stusps == "WY"
           )

# make a single polygon of the Rocky Mountain and Great Plains regions
# https://mgimond.github.io/Spatial/vector-operations-in-r.html
rm_gp_bdy <- state_bdy %>%
  st_union(.,
           by_feature = FALSE)

# make polygons of aiannh
tribal_lands <- tribal_lands_rm_gp %>%
  st_union(.,
           by_feature = FALSE)

# intersect eco_l3 by the Rocky Mountain and Great Plains region boundary
eco_l3_rm_gp <- st_intersection(eco_l3_proj, rm_gp_bdy)

# clean up Global Environment
rm(aiannh_table,
   eco_l3_proj,
   eco_l3,
   state_bdy_usa,
   tribal_lands_usa,
   crs_geom_eco,
   crs_geom_st_bdy_usa
   )

```

```{r 02b_visualize_eco_l3_bdry_w_rm_gp_region}

# orig data
# make a quick plot
# ggplot() +
#   geom_sf(data = eco_l3_rm_gp,
#           aes(fill = us_l3name,)) +
#   geom_sf(data = state_bdy,
#           fill = "transparent")

# cleaner theme
ggplot() +
  geom_sf(data = eco_l3_rm_gp,    # Fill regions based on ecological names
          aes(fill = us_l3name)
          ) +  
  geom_sf(data = state_bdy,       # State boundaries with no fill
          fill = NA,
          color = "black",
          size = 0.5
          ) +
  labs(title = "Ecological Regions with State Boundaries",
       fill = "Ecological Region") +  # Adding title and legend title
  scale_fill_viridis_d() +  # A color scale that's visually appealing and accessible
  theme_minimal()  # A clean theme

```

```{r 02c_visually_explore_l1_great-plains}

# Select the Great Plains Level 1 ecoregion
eco_l3_gp <- eco_l3_rm_gp %>%
  filter(na_l1name == "GREAT PLAINS")

# Plot with text labels
# ggplot() +
#   geom_sf(data = eco_l3_gp,
#           aes(fill = us_l3name)) +
#   geom_sf(data = state_bdy,
#           fill = "transparent")

# cleaner theme
ggplot() +
  geom_sf(data = eco_l3_gp,    # Fill regions based on ecological names
          aes(fill = us_l3name)
          ) +  
  geom_sf(data = state_bdy,       # State boundaries with no fill
          fill = NA,
          color = "black",
          size = 0.5
          ) +
  labs(title = "Great Plains Ecoregions with State Boundaries",
       fill = "Ecological Region") +  # Adding title and legend title
  scale_fill_viridis_d() +  # A color scale that's visually appealing and accessible
  theme_minimal()  # A clean theme

```

```{r 02d_visually_explore_l2_semi-arid-prairies}

# Select the Great Plains Level 1 ecoregion
eco_l3_semi <- eco_l3_rm_gp %>%
  filter(na_l2name == "SOUTH CENTRAL SEMI-ARID PRAIRIES" |
         na_l2name == "WEST-CENTRAL SEMI-ARID PRAIRIES")

# Plot with text labels
# ggplot() +
#   geom_sf(data = eco_l3_semi,
#           aes(fill = us_l3name)) +
#   geom_sf(data = state_bdy,
#           fill = "transparent") +
#   geom_sf(data = tribal_lands_rm_gp,
#           aes(fill = aiannhce),
#           show.legend = c(fill = FALSE))

# cleaner theme
ggplot() +
  geom_sf(data = eco_l3_semi,    # Fill regions based on ecological names
          aes(fill = us_l3name)
          ) +  
  geom_sf(data = state_bdy,       # State boundaries with no fill
          fill = NA,
          color = "black",
          size = 0.5
          ) +
   geom_sf(data = tribal_lands,
            fill = "gray50",
            alpha = 0.5
#           aes(fill = aiannhce,
#           show.legend = FALSE)
           ) +
  labs(title = "Semi-Arid Great Plains Ecoregions with State Boundaries",
       fill = "Ecological Region") +  # Adding title and legend title
  scale_fill_viridis_d() +  # A color scale that's visually appealing and accessible
  theme_minimal()  # A clean theme

```

```{r 02e_visually_explore_l3_semi-arid-prairies_not_glaciated}

# Select the Great Plains Level 1 ecoregion
eco_l3_semi_ng <- eco_l3_semi %>%
  filter(na_l3name != "Northwestern Glaciated Plains")

# # Plot with text labels
# ggplot() +
#   geom_sf(data = eco_l3_semi_ng,
#           aes(fill = us_l3name,
#               show.legend = FALSE)
#           ) +
#   geom_sf(data = state_bdy,
#           fill = "transparent") +
#   geom_sf(data = tribal_lands_rm_gp,
#           alpha = 0.5) +
#   theme_minimal() +
#   ggtitle("Map of level-3 ecoregions") 

# cleaner theme
ggplot() +
  geom_sf(data = eco_l3_semi_ng,    # Fill regions based on ecological names
          aes(fill = us_l3name)
          ) +  
  geom_sf(data = state_bdy,       # State boundaries with no fill
          fill = NA,
          color = "black",
          size = 0.5
          ) +
  labs(title = "Non-glaciated Semi-Arid Great Plains Ecoregions",
       fill = "Ecological Region") +  # Adding title and legend title
  scale_fill_viridis_d() +  # A color scale that's visually appealing and accessible
  theme_minimal()  # A clean theme

```


