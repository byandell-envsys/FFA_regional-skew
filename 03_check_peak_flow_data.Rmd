---
title: "Peak flow locs for Northwestern Great Plains and High Plains ecoregion"
author: "CJ Tinant"
date: "`r Sys.Date()`"
output: html_document
---

<!--
PURPOSE: Prepare peak flow data for analysis 

METHODS:
1. Check peak flow record flags.

2. Omit records with:
* "3" -- "Discharge affected by Dam Failure",
* "5" -- "Discharge affected to unknown degree by Regulation or Diversion",
* "6" -- "Discharge affected by Regulation or Diversion",
* "C" -- "All or part of the record affected by Urbanization, Mining, Agricultural changes, Channelization, or other",

3. Check records with:
* "4" -- "Discharge less than indicated value which is Minimum Recordable Discharge at this site",
* "A" -- "Year of occurrence is unknown or not exact",
* "Bd" -- "Day of occurrence is unknown or not exact",
* "Bm" -- "Month of occurrence is unknown or not exact",
* "O", "Opportunistic value not from systematic data collection",

4. Keep records with
* "1" -- "Discharge is a Maximum Daily Average",
* "2" -- "Discharge is an Estimate",
* "7" -- "Discharge is an Historic Peak",
* "8" -- "Discharge actually greater than indicated value",
* "9" -- "Discharge due to Snowmelt, Hurricane, Ice-Jam or Debris Dam breakup",
* "F", "Peak supplied by another agency",
* "R", "Revised"

RESULTS
sites_peak -- 

DATA DICTIONARY
desc_peak_flag

omit               -- records omitted
omit_affected      -- records omitted because of affected discharge
omit_dam_fail      -- records omitted because of dam failure
omit_regulated     -- records omitted discharge regulation
omit_unkn_degr_reg -- records omitted unkn degr of regulation

peak_data_gt_20 -- peak flow records for sites with gt 20 yrs data
peak_data      -- peak flow records for unreg sites

peak_flag_summ -- USGS codes for data flags
peak_flags     -- peak flow records with flags

sites_gt_20        -- sites in study area with gt 20 yrs data (n = 518)
sites_peak_unreg  -- unregulated sites in study area w gt 20 yrs data (n = 331)

-->

```{r 00_setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# library
library(tidyverse)        # Load the 'Tidyverse' packages: ggplot2, dplyr, 
                          #   tidyr, readr, purrr, tibble, stringr, and forcats
library(dataRetrieval)    # Retrieval functions for USGS and EPA hydrology and
                          #   water quality data
library(sf)               # Simple features for R
library(Lmoments)         # L-moments and trimmed L-moments from the data
library(lmom)

```

```{r 01_import_peak-flow_pf-data_pf-station-metadata}

# get peakflow metadata
sites_gt_20 <- read_csv("data/sites_peak_gt_20.csv")

# get peakflow data
peak_data_gt_20 <- read_csv("data/data_peak_gt_20.csv",
                            col_types = cols(
                              .default = "?",
                              year_last_pk = "i"
                              ))

# get count of gages and observations
count_sites_gt_20 <- nrow(sites_gt_20)
count_peak_data_gt_20 <- nrow(peak_data_gt_20)

```

```{r 02_make_pf-flag-descriptions}

desc_peak_flag <- tribble(
  ~peak_cd, ~peak_cd_descr,
  "1", "Discharge is a Maximum Daily Average",
  "2", "Discharge is an Estimate",
  "3", "Discharge affected by Dam Failure",
  "4", "Discharge less than indicated value which is Minimum Recordable Discharge at this site",
  "5", "Discharge affected to unknown degree by Regulation or Diversion",
  "6", "Discharge affected by Regulation or Diversion",
  "7", "Discharge is an Historic Peak",
  "8", "Discharge actually greater than indicated value",
  "9", "Discharge due to Snowmelt, Hurricane, Ice-Jam or Debris Dam breakup",
  "A", "Year of occurrence is unknown or not exact",
  "Bd", "Day of occurrence is unknown or not exact",
  "Bm", "Month of occurrence is unknown or not exact",
  "C", "All or part of the record affected by Urbanization, Mining, Agricultural changes, Channelization, or other",
  "F", "Peak supplied by another agency",
  "O", "Opportunistic value not from systematic data collection",
  "R", "Revised"
  )

```

```{r 03_pf_data_check_data_flags}

# tidy then check peak_data flags
peak_data_flags <- peak_data_gt_20 %>%
  select(-peak_va) %>%
  distinct() %>%
  filter(!is.na(peak_cd)) %>%
  separate(peak_cd, into = c("scratch_1",
                             "scratch_2",
                             "scratch_3",
                             "scratch_4",
                             "scratch_5"
                             ),
           sep = ",",
           remove = FALSE,
           extra = "merge") %>%
  pivot_longer(cols = starts_with("scratch")) %>%
  select(-c(peak_cd, name)) %>%
  rename(peak_cd = value) %>%
  distinct() %>%
  filter(!is.na(peak_cd)) %>%
  select(site_no, peak_dt, peak_cd) %>%
  group_by(peak_cd) %>%
  summarise(count = n())

peak_data_flags <- left_join(peak_data_flags, desc_peak_flag,
                             by = join_by(peak_cd))

```

```{r 04_pf_data_omit_records}

# pull records with dam fail, regulation, or discharge otherwise affected
omit_dam_fail <- peak_data_gt_20 %>%
  filter(peak_cd == "3")

omit_unkn_degr_reg <- peak_data_gt_20 %>%
  filter(peak_cd == "5")

omit_regulated <- peak_data_gt_20 %>%
  filter(peak_cd == "6")

omit_affected <- peak_data_gt_20 %>%
  filter(peak_cd == "C")

# remove omitted records from working df
data_omit <- bind_rows(omit_dam_fail,
                       omit_unkn_degr_reg,
                       omit_regulated,
                       omit_affected
                       )

# remove omitted data from orig data
scratch_data_unreg <- anti_join(peak_data_gt_20, data_omit)

# check that the count is true
check_count <- nrow(peak_data_gt_20) == nrow(data_omit) + nrow(scratch_data_unreg)

# clean up Global Environment
rm(list = ls(pattern = "omit_"))

```

```{r 05_pf_sites_separate_regulated_unregulated_sites}
# make an initial list of remaining gages and omitted gages
scratch_sites <- scratch_data_unreg %>%
  group_by(site_no) %>%
  summarise(pk_count = n())

scratch_sites_omit <- anti_join(sites_gt_20, scratch_sites)

scratch_sites_unreg_lt_20 <- scratch_sites %>%
  filter(pk_count < 20)

sites_omit <- bind_rows(scratch_sites_omit,
                        scratch_sites_unreg_lt_20)

sites_unreg <- anti_join(sites_gt_20, sites_omit,
                         by = join_by(site_no))

# check that the count is true
check_count <- nrow(sites_unreg) == nrow(sites_gt_20) - nrow(sites_omit)

count_sites_unreg <- nrow(sites_unreg)

# clean up Global Environment
rm(list = ls(pattern = "scratch"))

```

```{r 06_pf_data_separate_data_for_regulated_unregulated_sites}

# update df sites with regulation
peak_data_reg <- peak_data_gt_20 %>%
  filter(site_no %in% sites_omit$site_no)

# update working df for only unregulated sites
peak_data_unreg <- peak_data_gt_20 %>%
  filter(site_no %in% sites_unreg$site_no)

# check that the count is true
check_count <- nrow(peak_data_unreg) == nrow(peak_data_gt_20) - nrow(peak_data_reg)

count_data_unreg <- nrow(peak_data_gt_20) - nrow(peak_data_reg)

# clean up Global Environment
rm(list = ls(pattern = "omit"))
rm(peak_data_reg)
rm(peak_data_gt_20)

```

```{r 07_visually_check_results}

# load ecoregion shapefile -- local path
study_area_unproj <- st_read("data_spatial/data_spus_eco_l3/us_eco_l3.shp") %>%
  janitor::clean_names() %>%
  filter(na_l3name == "High Plains" |
         na_l3name == "Northwestern Great Plains") %>%
  st_transform(crs = 4269)

# convert stations into a spatial format (sf) objects
sites_gt_20 <- st_as_sf(sites_gt_20,
                    coords = c("dec_long_va",        # note x goes first
                                "dec_lat_va"),
                    crs = 4269,                     # crs for unprojected NAD83
                    remove = FALSE)                 # don't remove lat/lon cols

sites_unreg <- st_as_sf(sites_unreg,
                    coords = c("dec_long_va",        # note x goes first
                                "dec_lat_va"),
                    crs = 4269,                     # crs for unprojected NAD83
                    remove = FALSE)                 # don't remove lat/lon cols

# plot results
ggplot() +
  geom_sf(data = study_area_unproj,
          alpha = 0.3) +
  geom_sf(data = sites_gt_20,
          size = 0.2,
          color = "red",
          alpha = 0.4) +
  geom_sf(data = sites_unreg,
          size = 0.4,
          color = "black"
          ) +
  theme_bw() +
labs(
  title = "Final gage selection",
  subtitle = "Peak flow gages with at least 20 years of unregulated record"
)

# save plot of gages
ggsave("figures/gage-selection_final.png")

# clean up Global Environment
rm(sites_gt_20)
rm(study_area_unproj)

```

```{r 09_check_drop_NA_discharge_data}

peak_data_na <- peak_data_unreg %>%
  filter(is.na(peak_va))

sites_na <- peak_data_unreg %>%
  filter(site_no %in% peak_data_na$site_no) %>%
  arrange(site_no, gage_ht)

# drop observations with NA values
peak_data <- peak_data_unreg %>%
  filter(!is.na(peak_va))

# clean up Global Environment
rm(peak_data_unreg)
rm(sites_na)

```

# revise below

```{r 07_pf_data_check_dates}

# separate missing dates for recheck

# get missing peak flow dates
peak_date_miss <- peak_data_gt_20 %>%
  filter(is.na(peak_dt))

peak_data <- anti_join(peak_data_gt_20, peak_date_miss)

```


```{r 06_drop_cols, eval=FALSE}

sites_peak <- sites_peak %>%
  select(
    # no variance among station values
    -c(
      agency_cd,        # all = USGS
      site_tp_cd,       # all = ST
      data_type_cd,     # all = pk
      parm_cd,          # all = NA
      stat_cd,          # all = NA
      ts_id,            # all = 0
      loc_web_ds,       # all = NA
      medium_grp_cd,    # all = wat
      parm_grp_cd,      # all = ST
      srs_id,           # all = 0
      access_cd,        # all = 0
      # non-important vars
      alt_acy_va,
      coord_acy_cd,
      # not-needed ecoreg names
      na_l3code,
      na_l3name,
      na_l2code,
      na_l2name,
      na_l1code,
      na_l1name,
      l3_key,
      l2_key,
      l1_key,
      shape_leng,
      shape_area
    ))

# clean up Global Environment
rm(list = ls(pattern = "sites_pk"))
rm(list = ls(pattern = "study"))

```









```{r 04_pf_data_get_peak_months}

peak_months <- peak_data %>%
  mutate(peak_mon = month(peak_dt)
         ) %>%
  select(c(peak_dt, site_no, peak_mon))

peak_mon_ck <- peak_months %>%
  filter(is.na(peak_mon))



  group_by(site_no) %>%
  summarise(mon_mean = mean(peak_mon),
            mon_median = median(peak_mon),
            mon_sd = sd(peak_mon)
             ) %>%
  ungroup()

```

```{r 02_munge_pf_data_drop_vars, eval=FALSE}

# drop not needed vars

peak_data <- peak_data %>%
  select(-c(
    agency_cd,
    peak_tm,
    gage_ht,
    gage_ht_cd,
    ag_tm,
    ag_gage_ht,
    ag_gage_ht_cd,
    peak_dateTime,
    ag_dateTime,
    ag_dt,
    year_last_pk
  ))

```

```{r 04_munge_pf_metadata}

# Identify missing data
sites_gt_20_missing_data <- sites_peak %>%
  summarize(across(everything(), ~sum(is.na(.)))) %>%
  pivot_longer(cols = everything())

```



```{r fix_this_how_to_get_Lmoments}

moments <- peak_data %>%
  group_by(site_no) %>%
  samlmu(peak_data$peak_va, 4)

  summarise(moments = Lmoments(peak_data$peak_va))


```


<!--
# Ecoregion hierarchy
Northwestern Great Plains and High Plains region of the SOUTH CENTRAL SEMI-ARID PRAIRIES of the GREAT PLAINS ecoregion

## Next steps
create an inline unzip
unzip /path/to/your/file.zip -d /path/to/destination/folder

-- need to add ecoreg when joining


* sync personal and group Zotero library for FFA
https://guides.library.oregonstate.edu/c.php?g=359201&p=2426111
https://www.zotero.org/groups/5473862/olc_flood-frequency


## Helpful references:
GIT issues--
[GIT issues](https://dangitgit.com/)

Spatial data issues--
[Intro to spatial data in R](https://www.r4wrds.com/intro/m_intro_mapmaking)
[Overview of Coordinate Reference Systems (CRS) in R](https://www.nceas.ucsb.edu/sites/default/files/2020-04/OverviewCoordinateReferenceSystems.pdf)
[Geocomputation with R](https://r.geocompx.org/)

References:
[dataRetrieval tutorial](https://waterdata.usgs.gov/blog/dataretrieval/)

[USGS watermapper](https://maps.waterdata.usgs.gov/mapper/index.html)
-->






