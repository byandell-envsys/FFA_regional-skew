---
title: "Milestone 01 â€” Download and Prepare Covariates"
subtitle: "Establishing a Reproducible Framework for Regional Skew Estimation"
author: "C.J. Tinant"
date: "`r format(Sys.Date(), '%B %d, %Y')`"
output:
  github_document:
    toc: true
    toc_depth: 2
params:
  version: "v0.5"
editor_options:
  markdown:
    wrap: 72
---

## Overview of `r params$version`

This document describes the structure and metadata setup completed for **Milestone `r params$version`**.

### Summary
Initiate acquisition, validation, and preparation of climate, terrain, and location-based covariates for use in regional skew estimation models.

See [`spatial_data_preparation_checklist.md`](../docs/spatial_data_preparation_checklist.md) for a reusable checklist used to guide and document preprocessing steps across spatial layers.

### Goals

- Downloading and staging spatial datasets (ecoregions, PRISM, NED, etc.)
- Documenting file sources and formats in `metadata/` and `docs/`
- Conducting initial QA checks on file completeness and coordinate reference systems

-   Acquire, check, and document all raw covariate datasets

-   Write or Refactor Download Scripts

-   Spatial File QA + Metadata Logging

-   Version Control & Tagging

## Notes

-   This milestone builds on `v0.3-structure-refactor`

-   README-style documentation will be embedded in this .Rmd file for reproducibility

### Naming convention:

-   Subdirectory naming follows as shown in **Project Structure**. Example folder names:

    -   /data_raster_raw/epa_landcover_2016/  

    -   /data_raster_raw/usgs_nhdplusv2/  

    -   /data_raw/prism_ppt_normals/

    -   Script naming follows: `milestone + domain + covariate + source` 

-   Data naming follows: [source]_[layer]_[year|version]_[status].[ext]. Example filenames:

    -   prism_ppt_30yrnormals_raw.bil

    -   usgs_nhdplus_catchments_v21_raw.shp

    -   epa_nlcd_2021_raw.tif

    -   census_county_boundaries_2020_raw.gpkg

See: `R/00_setup/` and `data/raw/` for implementation scripts and acquired data

<!--

    Commit & Tag When Stable

        Push milestone script changes and metadata updates

        Use tags like v0.5-prism-dl or milestone-01-initial

## Tag when complete
git tag -a milestone-01-complete -m "Milestone 01: Covariate acquisition and QA complete"
git push origin milestone-01-complete

Next Steps for Milestone 01 â€“ Download and QA Raw Covariate Data

ðŸ”¹ 02. Write or Refactor Download Scripts

.... Look through 01_get_spatial...R

    Begin modular scripts for each covariate domain.

    Optional: log intermediate outputs in data/meta/.

    ðŸ”² Break scripts into modular chunks by source:

        01a_get_prism.R

        01b_get_nlcd.R

        01c_get_ned_elev.R

        01d_get_stream_networks.R, etc.

    ðŸ”² Validate reproducibility with here(), glue(), and httr::GET() or download.file()

    ðŸ”² Save logs or hash summaries to /log/ or /data/meta/

ðŸ”¹ 03. Spatial File QA + Metadata Logging

        Check CRS, alignment, bounding box, resolution
        
    Validate spatial integrity (extent, projection, cell size, alignment)

    Create structured metadata and site-level extracted values
    
    ðŸ”² Write an R/01_download/01x_check_spatial_files.R

        Confirm CRS, resolution, bounding box, projection units

        Output to data/meta/spatial_covariate_summary.csv

ðŸ”¹ 04. Document Progress in milestone_01a_download_scripts.Rmd

    ðŸ”² Add a short narrative and chunk headers for each dataset

    ðŸ”² Use params$version to link to tag v0.5 (if applicable)

ðŸ”¹ 05. Version Control & Tagging

    ðŸ”² Commit regularly: "Download: Add script for PRISM data and raw file log"


## Longer-term Considerations

    We can build a targets pipeline incrementally if youâ€™d like.


Review Gage Locations (Filtered by Macrozone)

1.  Assign each gage to a macrozone using st_join():

```         
gages_macrozone <- st_join(gages_sf, macrozone_sf["macrozone"])
```

2.  gages_macrozone \<- st_join(gages_sf, macrozone_sf["macrozone"])

gages_macrozone %>%
  group_by(macrozone) %>%
  summarize(across(where(is.numeric), list(mean = mean, sd = sd), na.rm = TRUE))


You can visualize macrozones as basemap groups

Or compute zone-wide summaries for supporting tables or EDA


ðŸ§­ Bottom Line

Youâ€™re right to go with Use Gage Locations (Filtered by Macrozone) â€” it's more robust, interpretable, and directly connected to your outcome variable (station skew). Random samples are useful for some exploratory summaries, but not essential here.

## ðŸŒ± When Youâ€™re Ready to Grow Againâ€¦

Here are next-step seeds you might plant: 1. Finalize Milestone 01

Join covariates to each gage (with macrozone as a group)

2.  Begin Milestone 03 (Targets or Modeling)

    Start small: just one covariate, one model

    Or set up a {targets} pipeline to wrap download â†’ clean â†’ model

3.  Open a Future Milestone Planning Doc

You've already created notes/future_milestones.Rmd â€” thatâ€™s your strategic launchpad.

-->

# Project Structure

``` text
FFA_regional-skew/
â”œâ”€â”€ .gitignore                    # Prevents sensitive/local files from being pushed
â”œâ”€â”€ arcgis_project/               # Stores `.aprx` and layer files from ArcGIS 
                                  #   Pro workflows

â”œâ”€â”€ data/ 
    â”œâ”€â”€ meta/                     # Metadata
        â”œâ”€â”€ prism/
        |   â””â”€â”€ ppt_30yrnormals/
        |        â””â”€â”€ prism_ppt_30yrnormals_raw.bil
        â”œâ”€â”€ epa/
        |    â””â”€â”€ nlcd_2016/
        â”‚       â””â”€â”€ epa_nlcd_2016_raw.tif
        â””â”€â”€ usgs/
            â””â”€â”€ nhdplus/
            |   â””â”€â”€ usgs_nhdplus_catchments_v21_raw.shp
            â””â”€â”€ waterdata/
                â”œâ”€â”€ sites_all_in_bb.csv
                â””â”€â”€ sites_all_peak_in_bb.csv

    â”œâ”€â”€ processed/               # Cleaned, derived datasets
        â”œâ”€â”€ prism/
        |   â””â”€â”€ ppt_30yrnormals/
        |        â””â”€â”€ prism_ppt_30yrnormals_raw.bil
        â”œâ”€â”€ epa/
        |    â””â”€â”€ nlcd_2016/
        â”‚       â””â”€â”€ epa_nlcd_2016_raw.tif
        â””â”€â”€ usgs/
            â””â”€â”€ nhdplus/
            |   â””â”€â”€ usgs_nhdplus_catchments_v21_raw.shp
            â””â”€â”€ waterdata/
                â”œâ”€â”€ sites_all_in_bb.csv
                â””â”€â”€ sites_all_peak_in_bb.csv

    â”œâ”€â”€ raw/                      # Unmodified input data 
        â”œâ”€â”€ prism/
        |   â””â”€â”€ ppt_30yrnormals/
        |        â””â”€â”€ prism_ppt_30yrnormals_raw.bil
        â”œâ”€â”€ epa/
        |    â””â”€â”€ nlcd_2021/
        â”‚       â””â”€â”€ epa_nlcd_2021_raw.tif
        â””â”€â”€ usgs/
            â””â”€â”€ nhdplus/
            |   â””â”€â”€ usgs_nhdplus_catchments_v21_raw.shp
            â””â”€â”€ waterdata/
                â”œâ”€â”€ sites_all_in_bb.csv
                â””â”€â”€ sites_all_peak_in_bb.csv

â”œâ”€â”€ docs/                     # Project documentation, e.g., final reports, 
                              #   manuscripts, proposal materials. 
                              # Reference documentation like README-style guides. 
                              # Metadata crosswalks and data dictionaries
                              # review or publication. 
                              # Files you reference in Quarto/PDF reports or posters

â”œâ”€â”€ FFA_regional-skew.Rproj   # RStudio project file for launching the 
                              # workspace. Keep this in the root.
â”œâ”€â”€ log/                      # For shell logs or targets progress reports 
â”œâ”€â”€ notebooks/                # For ad hoc .Rmd or .qmd experiments 
â”œâ”€â”€ notes/                    # Personal or team notes, meeting logs, brainstorms
                              #   Could be transitioned to Markdown or Quarto as
                              #   the project matures

â”œâ”€â”€ output/                   # Intermediate outputs (e.g., `.Rds`, `.csv`, `.tif`)
                              # Next Steps: Add subfolders like `extracted/`,
                              #   `joined/`, or date-stamped folders |
â”‚   â”œâ”€â”€ figs/                 # Plots and maps
â”‚   â”œâ”€â”€ models/               # Model objects (.rds)
â”‚   â””â”€â”€ tables/               # Summary tables (.csv, .html)

â”œâ”€â”€ R/                        # All analysis scripts (milestone-organized)
â”‚   â”œâ”€â”€ 01_download/          # NWIS, PRISM, Ecoregions
â”‚   â”œâ”€â”€ 02_clean/             # Filtering, QA, station skew
â”‚   â”œâ”€â”€ 03_covariates/        # Climate, topography, land cover
â”‚   â”œâ”€â”€ 04_modeling/          # GAMs, Elastic Net, correlation
â”‚   â”œâ”€â”€ 05_eval/              # Model diagnostics, residuals, validation
â”‚   â””â”€â”€ utils/                # Reusable functions
â”‚       â””â”€â”€ f_process_geometries.R

â”œâ”€â”€ README.md                     # Rendered Markdown output.  GitHub-compatible
                                  #   plain-text overview. Use for quick 
                                  #   navigation, build instructions, etc. 
â”œâ”€â”€ README.Rmd                    # Workflow overview (editable).  Richer,
                                  #   knit-ready documentation with figures, 
                                  #  tables, and references. Can generate 
                                  #   HTML/PDF documentation from this file

â”œâ”€â”€ reports/                      # analysis narratives, usually knitted `.Rmd` 
                                  #   or `.qmd` output. Next Steps: Consider 
                                  #   `reports/final/`, `reports/draft/` 
                                  #   structure if versioning

â”œâ”€â”€ results/                      # Manuscript-ready outputs, model metrics, 
                                  #   final figures, tables, model outputs for 
                                  #   publication or reporting Next Steps: 
                                  #   Organize by milestone or product:
                                  #     `maps/`, `tables/`, `models/`
â”‚   â”œâ”€â”€ posterdown/                 # Poster files and assets
â”‚   â””â”€â”€ slides/                     # Slide decks or visualizations

â”œâ”€â”€ to_check/                    # Temporary holding area for uncertain or 
                                 #   transitional files needing review or QA. 
                                 # Next Steps: Consider renaming to `sandbox/` 
                                 # and clearing regularly.
```

# `r params$version` â€“ Download and Prepare Covariates

# `r params$version` Tasklist
| Step    | Task                                                      | Status |
|---------|-----------------------------------------------------------|--------|
| 0.5.1   | Refine the Covariate Inventory                            |  [ ]   |
| 0.5.1.5 | Document inputs, outputs, assumptions                     |  [ ]   |
| 0.5.2   | Update folder structure for data/                         |  [ ]   |
| 0.5.3   | Create downloads scripts for each domain and covariate    |  [ ]   |
| 0.5.3.5 | Validate chunk headers in .Rmd files ({r name, eval=} )   |  [ ]   |
| 0.5.4   | Standardize and validate metadata for downloads           |  [ ]   |
| 0.5.4.5 | Validate spatial coverage and CRS for covariates          |  [ ]   |
| 0.5.5   | Create README-style notes for scripts in milestone folder |  [ ]   |
| 0.5.5.5 | Add file size / resolution audit to .Rmd                  |  [ ]   |
| 0.5.6   | Add ref. links to documentation e.g., PRISM, USGS, NLCD   |  [ ]   |
| 0.5.7   | Knit milestone and data dictionary .Rmd files to PDF      |  [ ]   |
| 0.5.8   | Document changes in 01_download README.Rmd                |  [ ]   |
| 0.5.9   | Commit and tag `v0.5-download-scripts`                    |  [ ]   |

### Step 0.5.1 â€” Refine the Covariate Inventory

**Actions** 

-   Final list of covariates by domain (climate, terrain, land cover)

-   Document Filenames, expected sources, priority, and version tracking

**Reason (Before):** 

**Result (After):** 

1. Added docs/spatial_data_preparation_checklist.md. 

2. Updated: `data/meta/covariates_metadata_schema.csv`

3. All covariates included in this phase are considered core inputs for regional skew modeling. These variablesâ€”derived from climate, terrain, and location dataâ€”were selected based on prior studies, ecological relevance, and data availability. No optional or exploratory variables have been included in this milestone.

4. Created: `docs/spatial_data_preparation_checklist.md`

5. Created: `docs/covariate_source_inventory.md`

### Step 0.5.2 â€” Update folder structure for data/

**Actions** 

   - Consider backing up entire project before file moves

   - Update any hardcoded paths in scripts

**Reason (Before):** 

**Result (After):** 

### Step 0.5.3 â€” Create downloads scripts for each domain and covariate

**Actions** 

**Reason (Before):** 

**Result (After):** 

### Step 0.5.4 â€” Standardize and validate metadata for downloads

**Actions** 

**Reason (Before):** 

**Result (After):** 

### Step 0.5.5 â€” Create README-style notes for scripts in milestone folder

**Actions** 

**Reason (Before):** 

**Result (After):** 

### Step 0.5.6 â€” Add reference links to documentation e.g., PRISM, USGS, NLCD

**Actions** 

**Reason (Before):** 

**Result (After):** 

### Step 0.5.7 â€” Knit milestone and data dictionary .Rmd files to PDF

**Actions** 

**Reason (Before):** 

**Result (After):** 

### Step 0.5.8 â€” Document changes in 01_download README.Rmd

**Actions** 

**Reason (Before):** 

**Result (After):** 

### Step 0.5.9 â€” Commit and tag `v0.5-download-scripts`

**Actions** 

**Reason (Before):** 

**Result (After):** 

